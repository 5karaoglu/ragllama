version: '3.8'

services:
  rag-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    volumes:
      # Veri dosyasını bağla
      - ./Book1.json:/app/Book1.json
      - ./document.pdf:/app/document.pdf
      # Model ve indeks önbelleklerini kalıcı hale getir
      - model_cache:/app/model_cache
      - embedding_cache:/app/embedding_cache
      - storage:/app/storage
      - pdf_storage:/app/pdf_storage
    environment:
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=0,1  # İki GPU'yu da görünür yap
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512  # CUDA bellek ayarlarını artır
      - TRANSFORMERS_CACHE=/app/model_cache  # Transformers önbelleğini ayarla
      - HF_HOME=/app/model_cache  # HuggingFace önbelleğini ayarla
      - OMP_NUM_THREADS=8  # CPU iş parçacığı sayısını sınırla
      - TOKENIZERS_PARALLELISM=true  # Tokenizer paralelliğini etkinleştir
    restart: unless-stopped
    runtime: nvidia  # NVIDIA runtime'ı açıkça belirt
    # GPU desteği ve kaynak sınırlamaları
    deploy:
      resources:
        limits:
          memory: 48G  # Bellek sınırını artır (14B model için)
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']  # İlk iki GPU'yu kullan (indeks 0 ve 1)
              capabilities: [gpu, utility, compute]  # Tüm GPU yeteneklerini etkinleştir
    tmpfs:
      - /tmp:size=10G  # /tmp dizinine 10GB alan ayır
    shm_size: '10gb'  # Shared memory boyutunu artır
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/status"]
      interval: 60s  # Kontrol aralığını artır
      timeout: 20s  # Zaman aşımını artır
      retries: 3
      start_period: 300s  # Başlangıç süresini artır (büyük model yükleme süresi için)

volumes:
  model_cache:
  embedding_cache:
  storage:
  pdf_storage: 